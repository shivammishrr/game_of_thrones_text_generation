{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\nimport re\nfrom nltk.corpus import stopwords\nimport string\n\nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.utils import pad_sequences\nfrom keras.utils.vis_utils import plot_model\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D\nfrom tensorflow.keras.optimizers import Adam\n\nimport pickle","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"def load_data(filename):\n  # open the file as read only\n  file = open(filename, 'r')\n  # read all text\n  text = file.read()\n  # close the file\n  file.close()\n  return text\ndata = load_data(r\"/kaggle/input/gameofthrones/got1.txt\")\ndata = data[:1200000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[:1000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Corpus","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n  sample = text\n  sample = re.sub('[%s]' % re.escape(string.punctuation), '', sample)\n  sample = [word for word in sample.split() if word.isalpha()]\n  sample = [word.lower() for word in sample]\n  sample = \" \".join(sample)\n\n  return sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_data = clean_text(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cleaned_data[:100]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(x = [\"Total words\", \"Unique words\"],\n        height=[len(cleaned_data.split()), len(set(cleaned_data.split()))],\n        color=sns.color_palette('pastel'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total Tokens: %d' % len(cleaned_data.split()))\nprint('Unique Tokens: %d' % len((set(cleaned_data.split()))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_doc = []\nseq_len = 50\nl = seq_len + 1\ntokens = [w for w in cleaned_data.split()]\n\nfor i in range(l, len(tokens)):\n\n    seq = tokens[i-l:i]\n\n    line = ' '.join(seq)\n    sequence_doc.append(line)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequence_doc","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(sequence_doc)\nsequences = tokenizer.texts_to_sequences(sequence_doc)\n\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sequences = np.array(sequences)\nX, y = sequences[:,:-1], sequences[:,-1]\ny = to_categorical(y, num_classes=vocab_size)\n\nseq_length = X.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Perpare Model","metadata":{}},{"cell_type":"code","source":"def define_model(vocab_size, seq_length):\n    model = Sequential()\n    model.add(Embedding(vocab_size, 100, input_length=seq_length))\n    model.add(LSTM(200, return_sequences=True))\n    model.add(LSTM(200))\n    model.add(Dense(200, activation='relu'))\n    model.add(Dense(vocab_size, activation='softmax'))\n    \n    # compile network\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    # summarize defined model\n    model.summary()\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = define_model(vocab_size, seq_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, batch_size=128, epochs=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('text_gen_model.h5')\n# save the tokenizer\npickle.dump(tokenizer, open('tokenizer_text_gen.pkl', 'wb'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Text Sequence","metadata":{}},{"cell_type":"code","source":"def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n    result = list()\n    in_text = seed_text\n    # generate a fixed number of words\n    for _ in range(n_words):\n    # encode the text as integer\n        encoded = tokenizer.texts_to_sequences([in_text])[0]\n        # truncate sequences to a fixed length\n        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n        # predict probabilities for each word\n        yhat = model.predict(encoded, verbose=0)\n        yhat = np.argmax(yhat,axis=1)\n        print(yhat)\n        # map predicted word index to word\n        out_word = ''\n        for word, index in tokenizer.word_index.items():\n            if index == yhat:\n                out_word = word\n                break\n        # append to input\n        in_text += ' ' + out_word\n        result.append(out_word)\n    return ' '.join(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_text = sequence_doc[np.random.randint(0,len(sequence_doc))]\nprint(seed_text + '\\n')\ngenerate_seq(model, tokenizer, seq_length, seed_text, 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_text = sequence_doc[np.random.randint(0,len(sequence_doc))]\nprint(seed_text + '\\n')\ngenerate_seq(model, tokenizer, seq_length, seed_text, 50)[:60]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}